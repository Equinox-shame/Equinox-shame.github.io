

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="梓曰">
  <meta name="keywords" content="">
  
    <meta name="description" content="前言 受到学校大创的不可抗力因素，以及某位摆烂队友的原因，最终选择方向为三维环境重建，而目前唯一的进度就只有这个。 因个人能力有限只能在本文中简单的对此项目进行复现，并指出一些方式来作为数据源给Instant-ngp作为输入源，进行训练 本次复现环境为 Windows10、CUDA 11.7、Python 3.8 (numpy 1.24.4、opencv-python 4.5.5.64)  项目地">
<meta property="og:type" content="article">
<meta property="og:title" content="NVDIA Instant-ngp 复现">
<meta property="og:url" content="https://equinox-shame.github.io/2023/09/19/NVDIA%20Instant-ngp%20%E5%A4%8D%E7%8E%B0/index.html">
<meta property="og:site_name" content="Autumnal">
<meta property="og:description" content="前言 受到学校大创的不可抗力因素，以及某位摆烂队友的原因，最终选择方向为三维环境重建，而目前唯一的进度就只有这个。 因个人能力有限只能在本文中简单的对此项目进行复现，并指出一些方式来作为数据源给Instant-ngp作为输入源，进行训练 本次复现环境为 Windows10、CUDA 11.7、Python 3.8 (numpy 1.24.4、opencv-python 4.5.5.64)  项目地">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/09/18/AUTV9oYxd1eQ8w2.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/18/pXGCAkwuifUMQyg.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/18/jE3t6SiVKhFUPL7.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/18/CB2iLpoE9naIdu4.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/18/J9uCYWQFsU7waDB.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/18/sex9OqJ1kh4dcLb.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/19/XwOytBf28diD4Nb.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/19/BzD29pmaXKyg3jV.png">
<meta property="article:published_time" content="2023-09-19T13:01:27.296Z">
<meta property="article:modified_time" content="2023-09-20T14:11:10.185Z">
<meta property="article:author" content="梓曰">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://s2.loli.net/2023/09/18/AUTV9oYxd1eQ8w2.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>NVDIA Instant-ngp 复现 - Autumnal</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"equinox-shame.github.io","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":"§"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"2aM6IUUWOeDGCZaDdRhrvLam-gzGzoHsz","app_key":"GQdXw2PjI9DScgw5QHVCZeYm","server_url":"https://2am6iuuw.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Autumnal Equinox</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="NVDIA Instant-ngp 复现"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-09-19 21:01" pubdate>
          2023年9月19日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6k 字
        
      </span>
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">NVDIA Instant-ngp 复现</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="前言">前言</h2>
<p>受到学校大创的不可抗力因素，以及某位摆烂队友的原因，最终选择方向为三维环境重建，而目前唯一的进度就只有这个。</p>
<p>因个人能力有限只能在本文中简单的对此项目进行复现，并指出一些方式来作为数据源给<code>Instant-ngp</code>作为输入源，进行训练</p>
<p>本次复现环境为 Windows10、CUDA 11.7、Python 3.8 (numpy 1.24.4、opencv-python 4.5.5.64)</p>
<blockquote>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/NVlabs/instant-ngp">NVlabs/instant-ngp: Instant neural graphics primitives: lightning fast NeRF and more (github.com)</a></p>
</blockquote>
<h2 id="论文简介">论文简介</h2>
<p>其论文标题翻译为中文为<code>使用哈希编码的多分辨率的即时神经图形原语</code>，我们从文中可以看到这样一张图</p>
<p><img src="https://s2.loli.net/2023/09/18/AUTV9oYxd1eQ8w2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>通过对比观察我们可以明显的看出对应的训练速度十分快速，而这也正是<code>NGP</code>所拥有的特点，与此同时其还支持<code>CUDA</code>进行编程，意味着我们可以使用N卡(Nvidia显卡)进行计算，加快对应的渲染速度</p>
<p>其对应的核心是<code>多分辨哈希编码</code>，相比<code>NeRF</code>的初始研究上，使用全连接神经网络的神经图形原语</p>
<p><code>NeRF</code>训练和评估是非常耗时的，而<code>NGP</code>设计了一个新的通用性的输入编码，它可以使用小型的网络同时又不会降低质量小型的网络，可以显著的减少浮点数的计算和内存访问</p>
<h3 id="输入编码的几种方式">输入编码的几种方式</h3>
<h4 id="频率编码">频率编码</h4>
<p>在原始的过程中其使用的是类似<code>cos</code>、<code>sin</code>的三角函数进行线性变换将低频转换为高频，以此将三维转换到高维中便于机器的学习</p>
<h4 id="参数编码">参数编码</h4>
<p>参数编码则是除了权重以及偏置职位，增加了一种辅助类型的数据结果，如网格或者是数字。此方式可能会消耗更多的内存，但是在此方式可以快速的进行训练，其在更新数据时只更新对应有影响的点位</p>
<h4 id="稀疏参数编码">稀疏参数编码</h4>
<p>在上面的密集型参数编码中使用了更多的存储，对于密集型参数编码存在两种浪费：</p>
<ol>
<li>在定义的空间中的空白部分是无意义的，但是会占用对应空间</li>
<li>密集型网格可能会对线性差值进行过度的平滑</li>
</ol>
<p>而稀疏参数编码则主要解决上述问题</p>
<p><strong>多分辨率哈希编码</strong></p>
<p>此编码变为<code>ngp</code>的一个核心内容</p>
<p><img src="https://s2.loli.net/2023/09/18/pXGCAkwuifUMQyg.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>假设这个表示神经网络： $$m(y, \varphi)$$</p>
<p>这个表示输入编码：$$y = enc(x,\theta)$$</p>
<p>在保证相同的质量的情况下，达到更好的训练速度，同时不会增加开销</p>
<p>第一步是将坐标点(x,y,z的真实值)转换为hash表中的index。途中蓝色粉色表示了不同的Level下的计算，不同的Level，网格的分辨率不同(上图中粉色网格小，粉色的分辨率就比蓝色的大，也就是蓝色的为更低级的层级)</p>
<p>第二步是在不同层级的hash table中找到目标值周围的八个点位的值，然后进行三线性插值</p>
<p>第三步就是将所有的Level的结果拼接，到这里就算完成了encoding</p>
<p>第四步就是送入神经网络即可 (如果两个点在索引到table上时为同一个点时，神经网络可以帮助我们解决哈希碰撞的问题)</p>
<p>NGP中不仅网络权重要进行训练，编码参数也要进行训练参数编码</p>
<p>其设计为 L 层，每层有 T 个特征向量，每个向量的维度是 F，有如下超参数</p>
<p><img src="https://s2.loli.net/2023/09/18/jE3t6SiVKhFUPL7.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>对于分每层的分辨率的计算依靠以下公式进行计算：</p>
<p><img src="https://s2.loli.net/2023/09/18/CB2iLpoE9naIdu4.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>而我们进行哈希索引到table的公式如下：</p>
<p><img src="https://s2.loli.net/2023/09/18/J9uCYWQFsU7waDB.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>上述公式中的 $$x_i$$ 的下标表示的是每一个xyz坐标上的一个分量，而 $$\pi_i$$ 被设计为一个巨大的质数</p>
<h2 id="源码简介">源码简介</h2>
<blockquote>
<p>项目地址(pytorch 实现)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/yashbhalgat/HashNeRF-pytorch">yashbhalgat/HashNeRF-pytorch: Pure PyTorch Implementation of NVIDIA paper on Instant Training of Neural Graphics primitives: https://nvlabs.github.io/instant-ngp/</a></p>
</blockquote>
<p>对应代码文件的核心为以下文件：</p>
<ol>
<li>
<p>opts</p>
</li>
<li>
<p>load_blender_data</p>
</li>
<li>
<p>run_nerf</p>
</li>
<li>
<p>nerf_helpers</p>
</li>
<li>
<p>nerf_model</p>
</li>
<li>
<p>render</p>
</li>
<li>
<p>inference</p>
</li>
</ol>
<h3 id="简易流程">简易流程</h3>
<ol>
<li>load_blender_data</li>
</ol>
<p>​    pose_spherical</p>
<ol start="2">
<li>create_nerf</li>
</ol>
<p>​    get_embedder</p>
<p>​       create Embedder</p>
<p>​    train中调用 lambda network_query_fn</p>
<ol start="3">
<li>in train iteration</li>
</ol>
<p>​    use_batching or not</p>
<p>​       get_rays</p>
<p>​    render (训练相关代码从此开始)</p>
<p>​       rays_0, rays_d = get_rays(H, W, K, c2w)</p>
<p>​       batchify_rays 分批处理</p>
<p>​           render_rays</p>
<p>​              准备工作</p>
<p>​                  分解出 rays_o, rays_d, viewdirs, near, fear</p>
<p>​                  构造采样点，给采样点加入随机噪声</p>
<p>​              Network_query_fn(pts, viewdirs, network_fn) 用在create_nerf中的lambda函数</p>
<p>​                  run_natwork</p>
<p>​                     xyz pe</p>
<p>​                     viewdirs pe</p>
<p>​                     batchify 在这里调用的fn就是 NeRF model</p>
<p>​                         将 pts, viewdirs 分开</p>
<p>​                         Pts 经过 8 层 linear</p>
<p>​                         8 层后的输出经过一层linear输出Alpha</p>
<p>​                         8层厚的输出再来一层linear(feature Linear)</p>
<p>​                         Feature 和input_view拼接 再经过一层linear</p>
<p>​                         最后在经过一层linear得到RGB</p>
<p>​              Raw2outputs 体渲染</p>
<p>​              Sample_pdf(z_vals_mid, weights, N_importance) 精细网络使用的采样方案</p>
<p>​              Network_query_fn(pts, views, network_fn) 第二次精细网络渲染</p>
<p>​              Raw2outputs 体渲染</p>
<p>​    Img2mse</p>
<p>​    Mse2psnr</p>
<p>​    调整学习率</p>
<p>​    定期保存模型，定期生成测试视频，定期渲染测试数据</p>
<h2 id="测试">测试</h2>
<p>为保证训练效率，此次复现工作主要采用CUDA实现版本完成</p>
<blockquote>
<p>项目链接：<a target="_blank" rel="noopener" href="https://github.com/NVlabs/instant-ngp">NVlabs/instant-ngp: Instant neural graphics primitives: lightning fast NeRF and more (github.com)</a></p>
</blockquote>
<h3 id="准备工作-——-环境搭建">准备工作 —— 环境搭建</h3>
<p>在编译instant_ngp代码之前需要准备以下几样东西：</p>
<ul>
<li>Visual Studio 2019。必须是2019，当然我只在2019上编译过，没有在其他版本的Visual Studio上尝试过，但是听说只有Visual Studio 2019才可以。</li>
<li>cuda。官方给的是cuda v10.2以上，我使用的是cuda11.6，我使用的显卡是3090，之前用的cuda11.3，但是好像失败了，就又安装了11.6，如果你的cuda版本不能用，又不想卸载之前的cuda，那么我建议安装两个版本的cuda，根据情况切换，具体操作网上有很多，大家自行查看。当然，还要下载对应的cudnn。</li>
<li>Cmake。官网建议3.21以上。</li>
<li>python。官网建议3.7及其以上。非必须，但是建议安装。</li>
<li>OptiX。官网建议7.3以上。非必选，但是意见安装。</li>
</ul>
<p>以上所有内容安装之后一定要检查环境，是否将路径添加到环境中。</p>
<p><code>TODO： 等后期补充详细信息</code></p>
<h3 id="运行截图">运行截图</h3>
<p><img src="https://s2.loli.net/2023/09/18/sex9OqJ1kh4dcLb.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h2 id="扩展">扩展</h2>
<p>上述过程中我们已经将对应的论文进行复现，以及论文中相关的测试数据我们也可以成功的复现，此处我们添加一些我们自己的扩展数据，主要用到<code>colmap</code>、<code>Python-Opencv</code>以及<code>numpy</code>来进行完成对应工作</p>
<h3 id="Colmap">Colmap</h3>
<p><code>colmap</code>（Structure-from-Motion and Multi-View Stereo）是一个功能强大的开源软件包，用于从图像序列中重建三维场景。它结合了结构从运动（Structure-from-Motion，SfM）和多视角立体（Multi-View Stereo，MVS）的技术，能够从一组图像中估计相机的位姿、场景的几何结构以及像素级的深度信息。</p>
<p><code>colmap</code>的主要功能包括：</p>
<ol>
<li>图像导入与管理：<code>colmap</code>支持导入常见的图像格式，并提供一个图像数据库来管理和组织您的图像数据。</li>
<li>特征提取与匹配：<code>colmap</code>可以自动从图像中提取特征点，例如SIFT、SURF等，并使用特征匹配算法（例如基于描述符的匹配）在不同图像之间建立特征点的对应关系。</li>
<li>相机定位与三维重建：<code>colmap</code>利用图像的特征匹配信息来估计相机的位姿（旋转和平移矩阵），并同时进行三维场景的重建。它使用了一种增量式的方法，逐步优化相机位姿和场景的几何结构。</li>
<li>稠密点云重建与立体匹配：<code>colmap</code>可以进一步提供稠密的三维点云重建和立体匹配的功能，通过将多个视角的信息融合在一起，生成更密集的场景表示。</li>
<li>导出与可视化：<code>colmap</code>支持导出重建结果的各种格式，包括点云、相机位姿、表面模型等。此外，它还提供了一些可视化工具，用于查看和分析重建结果。</li>
</ol>
<p><code>colmap</code>的优点之一是其开源性质，使得研究者和开发者可以自由地使用、修改和扩展其功能。它在学术界和工业界都被广泛使用，用于各种计算机视觉和三维重建任务，例如增强现实、虚拟现实、机器人导航等。</p>
<h3 id="拆分视频">拆分视频</h3>
<p>通常来说我们所拿到的数据源是一般为视频文件，我们需要从中拿到相机的位姿数据则需要我们使用<code>colmap</code>来完成，<code>colmap</code>获取相机位姿之前我们需要使用<code>Python-Opencv</code>来帮组我们对视频图像流进行一定的优化处理，我们编写以下脚本来进行拆分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter_similar_frames</span>(<span class="hljs-params">frames, threshold</span>):</span><br>    filtered_frames = []<br>    prev_frame = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> frames:<br>        <span class="hljs-keyword">if</span> prev_frame <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            filtered_frames.append(frame)<br>            prev_frame = frame<br>            <span class="hljs-keyword">continue</span><br><br>        diff = cv2.absdiff(frame, prev_frame)<br>        similarity = np.mean(diff)<br><br>        <span class="hljs-keyword">if</span> similarity &gt; threshold:<br>            filtered_frames.append(frame)<br>            prev_frame = frame<br><br>    <span class="hljs-keyword">return</span> filtered_frames<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">split_video</span>(<span class="hljs-params">video_path, output_folder, frame_interval, similarity_threshold</span>):</span><br>    cap = cv2.VideoCapture(video_path)<br>    frame_count = <span class="hljs-number">0</span><br>    frames = []<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        ret, frame = cap.read()<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ret:<br>            <span class="hljs-keyword">break</span><br><br>        frame_count += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> frame_count % frame_interval == <span class="hljs-number">0</span>:<br>            frames.append(frame)<br><br>    filtered_frames = filter_similar_frames(frames, similarity_threshold)<br><br>    <span class="hljs-keyword">for</span> i, frame <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(filtered_frames):<br>        output_file = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;output_folder&#125;</span>/frame_<span class="hljs-subst">&#123;i&#125;</span>.jpg&quot;</span><br>        cv2.imwrite(output_file, frame)<br><br>    cap.release()<br><br><span class="hljs-comment"># 设置输入视频路径和输出文件夹路径</span><br>video_path = <span class="hljs-string">&quot;C:\\Users\\Equinox\\Desktop\\Challenge\\Instant-NGP\\data\\first_train\\test.mp4&quot;</span><br>output_folder = <span class="hljs-string">&quot;C:\\Users\\Equinox\\Desktop\\Challenge\\Instant-NGP\\data\\test\\data&quot;</span><br><br><span class="hljs-comment"># 设置每隔几帧保存一帧</span><br>frame_interval = <span class="hljs-number">3</span><br><br><span class="hljs-comment"># 设置相似帧的阈值，用于过滤相似帧</span><br>similarity_threshold = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># 拆分视频并过滤相似帧</span><br>split_video(video_path, output_folder, frame_interval, similarity_threshold)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Done!&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>上述代码中我们通过匹配对应的相似帧的阈值，以及相关的视频帧间隔来进行拆分，大致上我们拆分一个视频可以拿到大约150+左右的图片后便可以进行后续的工作</p>
<h3 id="图片训练">图片训练</h3>
<p>我们利用colmap进行获取相机位姿数据，并训练相关的深度图，大致可以得到以下图：</p>
<p><img src="https://s2.loli.net/2023/09/19/XwOytBf28diD4Nb.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>之后我们将其数据导出为<code>txt</code>，在这之前<code>NeRF</code>仍然无法处理这个数据，我们还需要使用一个脚本将其进行转换，此处用到<code>Nvidia</code>官方给出的<code>Python</code>脚本，<code>colmap2nerf.py</code>其提供以下内容:</p>
<ul>
<li><code>--video_in</code>：可选参数，指定要转换为图像的视频文件路径。</li>
<li><code>--video_fps</code>：可选参数，指定从视频中提取图像时的帧率。</li>
<li><code>--time_slice</code>：可选参数，指定从视频中提取图像的时间范围，格式为 <code>t1,t2</code>，表示从第 <code>t1</code> 秒到第 <code>t2</code> 秒的时间段。</li>
<li><code>--run_colmap</code>：可选参数，如果设置，则在图像文件夹上先运行 COLMAP。</li>
<li><code>--colmap_matcher</code>：可选参数，指定 COLMAP 应该使用的匹配器类型。可选值为 <code>exhaustive</code>、<code>sequential</code>、<code>spatial</code>、<code>transitive</code>、<code>vocab_tree</code>。</li>
<li><code>--colmap_db</code>：可选参数，指定 COLMAP 数据库文件的名称。</li>
<li><code>--images</code>：可选参数，指定图像文件夹的路径。</li>
<li><code>--text</code>：可选参数，指定 COLMAP 文本文件的路径。如果使用 <code>--run_colmap</code> 参数，则该路径将被自动设置。</li>
<li><code>--aabb_scale</code>：可选参数，指定场景的缩放因子。可选值为 <code>1</code>、<code>2</code>、<code>4</code>、<code>8</code>、<code>16</code>，其中 <code>1</code> 表示场景适合单位立方体，其他值是 2 的幂次。</li>
<li><code>--skip_early</code>：可选参数，指定跳过开始的图像数量。</li>
<li><code>--out</code>：可选参数，指定输出路径，用于保存转换后的相机位姿数据。</li>
</ul>
<p>此处我们主要使用<code>--images</code>、<code>--text</code>以及<code>--out</code>参数来将我们之前的东西进行转换</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python colmap2nerf.py --images 图片位置 --text colmap获取的相机位姿数据 --out transform.json<br></code></pre></td></tr></table></figure>
<p>拿到相关的匹配后的<code>json</code>数据后我们便可以将其丢入<code>NeRF</code>中进行处理了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">.\instant-ngp.exe 对应数据位置<br></code></pre></td></tr></table></figure>
<p>之后我们可以调整对应的训练参数，进行相应的训练即可</p>
<p>训练一段时间后我们可以得到以下图片：</p>
<p><img src="https://s2.loli.net/2023/09/19/BzD29pmaXKyg3jV.png" srcset="/img/loading.gif" lazyload alt=""></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>NVDIA Instant-ngp 复现</div>
      <div>https://equinox-shame.github.io/2023/09/19/NVDIA Instant-ngp 复现/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>梓曰</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年9月19日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/09/18/APEX%20%E6%B8%B8%E6%88%8F%E5%8E%8B%E6%9E%AA%E5%AE%8F%E9%80%86%E5%90%91/" title="APEX 游戏压枪宏逆向">
                        <span class="hidden-mobile">APEX 游戏压枪宏逆向</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"2aM6IUUWOeDGCZaDdRhrvLam-gzGzoHsz","appKey":"GQdXw2PjI9DScgw5QHVCZeYm","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":true,"recordIP":true,"serverURLs":"","emojiCDN":"//i0.hdslb.com/bfs/emote/","emojiMaps":{"脱单doge":"bf7e00ecab02171f8461ee8cf439c73db9797748.png","热":"4e58a2a6f5f1580ac33df2d2cf7ecad7d9ab3635.png","微笑":"685612eadc33f6bc233776c6241813385844f182.png","口罩":"3ad2f66b151496d2a5fb0a8ea75f32265d778dd3.png","doge":"3087d273a78ccaff4bb1e9972e2ba2a7583c9f11.png","妙啊":"b4cb77159d58614a9b787b91b1cd22a81f383535.png","OK":"4683fd9ffc925fa6423110979d7dcac5eda297f4.png","星星眼":"63c9d1a31c0da745b61cdb35e0ecb28635675db2.png","辣眼睛":"35d62c496d1e4ea9e091243fa812866f5fecc101.png","吃瓜":"4191ce3c44c2b3df8fd97c33f85d3ab15f4f3c84.png","滑稽":"d15121545a99ac46774f1f4465b895fe2d1411c3.png","呲牙":"b5a5898491944a4268360f2e7a84623149672eb6.png","打call":"431432c43da3ee5aab5b0e4f8931953e649e9975.png","歪嘴":"4384050fbab0586259acdd170b510fe262f08a17.png","调皮":"8290b7308325e3179d2154327c85640af1528617.png","翻白眼":"eba54707c7168925b18f6f8b1f48d532fe08c2b1.png","灵魂出窍":"43d3db7d97343c01b47e22cfabeca84b4251f35a.png","再见":"fc510306bae26c9aec7e287cdf201ded27b065b9.png","嗑瓜子":"28a91da1685d90124cfeead74622e1ebb417c0eb.png","笑哭":"c3043ba94babf824dea03ce500d0e73763bf4f40.png","藏狐":"ba0937ef6f3ccca85e2e0047e6263f3b4da37201.png","脸红":"0922c375da40e6b69002bd89b858572f424dcfca.png","给心心":"1597302b98827463f5b75c7cac1f29ea6ce572c4.png","嘟嘟":"abd7404537d8162720ccbba9e0a8cdf75547e07a.png","哦呼":"362bded07ea5434886271d23fa25f5d85d8af06c.png","喜欢":"8a10a4d73a89f665feff3d46ca56e83dc68f9eb8.png","酸了":"92b1c8cbceea3ae0e8e32253ea414783e8ba7806.png","嫌弃":"de4c0783aaa60ec03de0a2b90858927bfad7154b.png","大哭":"2caafee2e5db4db72104650d87810cc2c123fc86.png","害羞":"9d2ec4e1fbd6cb1b4d12d2bbbdd124ccb83ddfda.png","疑惑":"b7840db4b1f9f4726b7cb23c0972720c1698d661.png","喜极而泣":"485a7e0c01c2d70707daae53bee4a9e2e31ef1ed.png","奸笑":"bb84906573472f0a84cebad1e9000eb6164a6f5a.png","阴险":"ba8d5f8e7d136d59aab52c40fd3b8a43419eb03c.png","囧":"12e41d357a9807cc80ef1e1ed258127fcc791424.png","呆":"33ad6000d9f9f168a0976bc60937786f239e5d8c.png","大笑":"ca94ad1c7e6dac895eb5b33b7836b634c614d1c0.png","惊喜":"0afecaf3a3499479af946f29749e1a6c285b6f65.png"},"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://equinox-shame.github.io" target="_blank" rel="nofollow noopener"><span>梓曰</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
